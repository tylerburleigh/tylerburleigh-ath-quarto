<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Tyler Burleigh">
<meta name="description" content="In this post, I explore whether a random forest model can be improved by using random forest based multivariate outlier detection and imputation methods, and by reducing feature multicollinearity. Supporting the common wisdom that random forest models are robust to outliers and multicollinearity, these data cleaning steps led to only marginal improvements in out-of-sample model performance.">
<title>Using random forest based outlier detection to clean a training dataset | Tyler Burleigh – Tyler Burleigh</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<link href="../../../..//files/favico.png" rel="icon" type="image/png">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-dd08061cb7210c315e315379d94beb87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-1f84303a6b4423b6cbd3f2cacdf6faa2.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../../../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-PRHQZ8HPLB"></script><script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-PRHQZ8HPLB', { 'anonymize_ip': true});
</script><style>

      .quarto-title-block .quarto-title-banner {
        background: #170C3A;
      }
</style>
<meta property="og:title" content="Using random forest based outlier detection to clean a training dataset | Tyler Burleigh">
<meta property="og:description" content="In this post, I explore whether a random forest model can be improved by using random forest based multivariate outlier detection and imputation methods, and by reducing feature multicollinearity. Supporting the common wisdom that random forest models are robust to outliers and multicollinearity, these data cleaning steps led to only marginal improvements in out-of-sample model performance.">
<meta property="og:image" content="https://tylerburleigh.com/blog/2023/09/08/social-image.png">
<meta property="og:site_name" content="Tyler Burleigh">
<meta property="og:image:height" content="960">
<meta property="og:image:width" content="1344">
<meta name="twitter:title" content="Using random forest based outlier detection to clean a training dataset | Tyler Burleigh">
<meta name="twitter:description" content="In this post, I explore whether a random forest model can be improved by using random forest based multivariate outlier detection and imputation methods, and by reducing feature multicollinearity. Supporting the common wisdom that random forest models are robust to outliers and multicollinearity, these data cleaning steps led to only marginal improvements in out-of-sample model performance.">
<meta name="twitter:image" content="https://tylerburleigh.com/blog/2023/09/08/social-image.png">
<meta name="twitter:image-height" content="960">
<meta name="twitter:image-width" content="1344">
<meta name="twitter:card" content="summary_large_image">
</head>
<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner"><nav class="navbar navbar-expand-lg " data-bs-theme="dark"><div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">Tyler Burleigh</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
<li class="nav-item">
    <a class="nav-link" href="../../../../index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../cv/index.html"> 
<span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../research/index.html"> 
<span class="menu-text">Research</span></a>
  </li>  
</ul>
<ul class="navbar-nav navbar-nav-scroll ms-auto">
<li class="nav-item compact">
    <a class="nav-link" href="https://fosstodon.org/users/tylerburleigh" rel="me"> <i class="bi bi-mastodon" role="img" aria-label="mastodon">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://bsky.app/profile/tylerburleigh.bsky.social" rel="me"> <i class="bi bi-square" role="img" aria-label="bluesky">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/tylerburleigh" rel="me"> <i class="bi bi-github" role="img" aria-label="github">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/tylerburleigh" rel="me"> <i class="bi bi-linkedin" role="img" aria-label="linkedin">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:tylerburleigh@gmail.com" rel="me"> <i class="bi bi-envelope" role="img" aria-label="email">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
</div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav></header><!-- content --><header id="title-block-header" class="quarto-title-block default blog-post page-columns page-full"><div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Using random forest based outlier detection to clean a training dataset</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          In this post, I explore whether a random forest model can be improved by using random forest based multivariate outlier detection and imputation methods, and by reducing feature multicollinearity. Supporting the common wisdom that random forest models are robust to outliers and multicollinearity, these data cleaning steps led to only marginal improvements in out-of-sample model performance.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">machine-learning</div>
                <div class="quarto-category">R</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p><a href="https://www.tylerburleigh.com/">Tyler Burleigh</a> </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">Friday, September 8, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Contents</h2>
   
  <ul>
<li><a href="#the-challenge" id="toc-the-challenge" class="nav-link active" data-scroll-target="#the-challenge">The Challenge</a></li>
  <li><a href="#load-libraries" id="toc-load-libraries" class="nav-link" data-scroll-target="#load-libraries">Load libraries</a></li>
  <li><a href="#parallel-backend" id="toc-parallel-backend" class="nav-link" data-scroll-target="#parallel-backend">Parallel backend</a></li>
  <li><a href="#load-the-data" id="toc-load-the-data" class="nav-link" data-scroll-target="#load-the-data">Load the data</a></li>
  <li><a href="#traintest-split" id="toc-traintest-split" class="nav-link" data-scroll-target="#traintest-split">Train/test split</a></li>
  <li>
<a href="#model-pipeline-and-baseline" id="toc-model-pipeline-and-baseline" class="nav-link" data-scroll-target="#model-pipeline-and-baseline">Model pipeline and baseline</a>
  <ul class="collapse">
<li><a href="#model-pipeline" id="toc-model-pipeline" class="nav-link" data-scroll-target="#model-pipeline">Model pipeline</a></li>
  <li><a href="#baseline-performance" id="toc-baseline-performance" class="nav-link" data-scroll-target="#baseline-performance">Baseline performance</a></li>
  </ul>
</li>
  <li>
<a href="#outlier-detection-and-removal-imputation" id="toc-outlier-detection-and-removal-imputation" class="nav-link" data-scroll-target="#outlier-detection-and-removal-imputation">Outlier detection and removal / imputation</a>
  <ul class="collapse">
<li>
<a href="#outlier-detection" id="toc-outlier-detection" class="nav-link" data-scroll-target="#outlier-detection">1. Outlier detection</a>
  <ul class="collapse">
<li><a href="#univariate-outlier-detection" id="toc-univariate-outlier-detection" class="nav-link" data-scroll-target="#univariate-outlier-detection">Univariate outlier detection</a></li>
  <li><a href="#multivariate-outlier-detection" id="toc-multivariate-outlier-detection" class="nav-link" data-scroll-target="#multivariate-outlier-detection">Multivariate outlier detection</a></li>
  </ul>
</li>
  <li><a href="#outlier-removal-or-imputation" id="toc-outlier-removal-or-imputation" class="nav-link" data-scroll-target="#outlier-removal-or-imputation">2. Outlier removal or imputation</a></li>
  </ul>
</li>
  <li><a href="#feature-multicollinearity" id="toc-feature-multicollinearity" class="nav-link" data-scroll-target="#feature-multicollinearity">Feature multicollinearity</a></li>
  </ul></nav>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content"><section id="the-challenge" class="level1"><h1>The Challenge</h1>
<p>For this blog post, I will be tackling the Kaggle compettition <a href="https://www.kaggle.com/competitions/playground-series-s3e21/overview">Improve a Fixed Model the Data-Centric Way!</a></p>
<p>This is the challenge of the competition: Improve a dataset that is being used to train a random forest model. The model is fixed, so model performance can only be improved by modifying the dataset. In terms of dataset modifications, there are some additional limitations:</p>
<ul>
<li>Rows can be removed, but not added</li>
<li>Columns cannot be removed or added</li>
<li>Values in the dataset that are used to train the model can be transformed, but those transformations will not be applied to the validation dataset (which is held out until the challenge comes to an end)</li>
</ul>
<p>This means that many of the tools available to a data scientist for improving an ML model, such as hyperparameter tuning, or data pre-processing applied to both training and test/validation datasets, are not available. The best options, therefore, will be to find ways to clean the training dataset that will yield better performance in the untouched validation dataset.</p>
<p>In this post, I will explore whether the training data can be improved using multivariate outlier imputation and by reducing feature multicollinearity.</p>
</section><section id="load-libraries" class="level1"><h1>Load libraries</h1>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidymodels.tidymodels.org">tidymodels</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/imbs-hl/ranger">ranger</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/mfrasco/Metrics">Metrics</a></span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="parallel-backend" class="level1"><h1>Parallel backend</h1>
<div class="cell">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://doFuture.futureverse.org">doFuture</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://doFuture.futureverse.org/reference/registerDoFuture.html">registerDoFuture</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html">plan</a></span><span class="op">(</span><span class="va">multisession</span>, workers<span class="op">=</span><span class="fl">4</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="load-the-data" class="level1"><h1>Load the data</h1>
<div class="cell">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">sample_submission</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="st">'sample_submission.csv'</span>, show_col_types <span class="op">=</span> <span class="cn">F</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="traintest-split" class="level1"><h1>Train/test split</h1>
<div class="cell">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span><span class="va">train_ids</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">sample_submission</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/sample_n.html">sample_frac</a></span><span class="op">(</span><span class="fl">0.75</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">id</span></span>
<span><span class="va">test_ids</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">sample_submission</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="op">!</span><span class="va">id</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="va">train_ids</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">id</span></span>
<span><span class="va">train</span> <span class="op">&lt;-</span> <span class="va">sample_submission</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">id</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="va">train_ids</span><span class="op">)</span></span>
<span><span class="va">test</span> <span class="op">&lt;-</span> <span class="va">sample_submission</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">id</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="va">test_ids</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="model-pipeline-and-baseline" class="level1"><h1>Model pipeline and baseline</h1>
<section id="model-pipeline" class="level2"><h2 class="anchored" data-anchor-id="model-pipeline">Model pipeline</h2>
<p>Before doing anything else, I want to create a model pipeline function and establish a baseline of model performance. This pipeline and baseline model will allow me to quickly iterate, test, and benchmark changes to the training dataset.</p>
<div class="cell">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit_ranger_cv</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">train</span>, <span class="va">test</span>, <span class="va">model_name</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span>  <span class="va">model_ranger</span> <span class="op">&lt;-</span></span>
<span>    <span class="co"># The parameters here mirror those that</span></span>
<span>    <span class="co"># will be used in the competition model</span></span>
<span>    <span class="fu">rand_forest</span><span class="op">(</span>trees <span class="op">=</span> <span class="fl">1000</span>, </span>
<span>                min_n <span class="op">=</span> <span class="fl">7</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>    <span class="fu">set_engine</span><span class="op">(</span><span class="st">"ranger"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>    <span class="fu">set_mode</span><span class="op">(</span><span class="st">"regression"</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">workflow_ranger</span> <span class="op">&lt;-</span> </span>
<span>    <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>    <span class="fu">add_formula</span><span class="op">(</span><span class="va">target</span> <span class="op">~</span> <span class="va">.</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>    <span class="fu">add_model</span><span class="op">(</span><span class="va">model_ranger</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu">vfold_cv</span><span class="op">(</span><span class="va">train</span>, v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">fit_ranger</span> <span class="op">&lt;-</span> </span>
<span>    <span class="va">workflow_ranger</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>    <span class="fu">fit_resamples</span><span class="op">(</span><span class="va">folds</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Get in-sample performance over resamples</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="op">(</span><span class="va">fit_ranger</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu">collect_metrics</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">.metric</span> <span class="op">==</span> <span class="st">'rmse'</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">mean</span>, <span class="fl">3</span><span class="op">)</span> <span class="op">-&gt;</span> <span class="va">train_perf</span></span>
<span>  </span>
<span>  <span class="co"># Evaluate performance on out-of-sample (test) data</span></span>
<span>  <span class="va">ranger_fit</span> <span class="op">&lt;-</span> </span>
<span>    <span class="va">workflow_ranger</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu">fit</span><span class="op">(</span><span class="va">train</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Metrics/man/rmse.html">rmse</a></span><span class="op">(</span><span class="va">test</span><span class="op">$</span><span class="va">target</span>, <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">ranger_fit</span>, <span class="va">test</span><span class="op">)</span><span class="op">$</span><span class="va">.pred</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span> <span class="op">-&gt;</span> <span class="va">test_perf</span></span>
<span>  </span>
<span>  <span class="co"># Combine in-sample and out-of-sample into a dataframe</span></span>
<span>  <span class="va">df_perf</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>model <span class="op">=</span> <span class="va">model_name</span>,</span>
<span>                        train_perf <span class="op">=</span> <span class="va">train_perf</span>,</span>
<span>                        test_perf <span class="op">=</span> <span class="va">test_perf</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">df_perf</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="baseline-performance" class="level2"><h2 class="anchored" data-anchor-id="baseline-performance">Baseline performance</h2>
<div class="cell">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">baseline_fit</span> <span class="op">&lt;-</span> <span class="fu">fit_ranger_cv</span><span class="op">(</span><span class="va">train</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">id</span><span class="op">)</span>, <span class="va">test</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">id</span><span class="op">)</span>, <span class="st">'baseline'</span><span class="op">)</span></span>
<span><span class="va">baseline_fit</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     model train_perf test_perf
1 baseline      1.231     2.134</code></pre>
</div>
</div>
<p>I’m going to run that again so I can be sure the RNG seed is set properly and the results are reproducible – otherwise I’ll be chasing a moving target!</p>
<div class="cell">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">baseline_fit</span> <span class="op">&lt;-</span> <span class="fu">fit_ranger_cv</span><span class="op">(</span><span class="va">train</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">id</span><span class="op">)</span>, <span class="va">test</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">id</span><span class="op">)</span>, <span class="st">'baseline'</span><span class="op">)</span></span>
<span><span class="va">baseline_fit</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     model train_perf test_perf
1 baseline      1.231     2.134</code></pre>
</div>
</div>
</section></section><section id="outlier-detection-and-removal-imputation" class="level1"><h1>Outlier detection and removal / imputation</h1>
<p>Outlier detection, sometimes called anomaly detection, involves identifying values that are “extreme” in relation to other records in the dataset. For example, a value might be considered an outlier if it deviates from the mean by more than 3 standard deviations. The impact of outliers on model performance will depend on the model. Linear regressions are fairly sensitive to outliers, whereas random forest models tend to be fairly robust to them. Nevertheless, multivariate outliers can still be a source of noise in training datasets, particularly smaller datasets.</p>
<p>Here I will consider several methods of outlier detection, pick one, and then proceed to consider removal/imputation.</p>
<section id="outlier-detection" class="level2"><h2 class="anchored" data-anchor-id="outlier-detection">1. Outlier detection</h2>
<section id="univariate-outlier-detection" class="level3"><h3 class="anchored" data-anchor-id="univariate-outlier-detection">Univariate outlier detection</h3>
<p>One simple univariate outlier detection method involves a “Z-score threshold”. In a normally distributed dataset, 99% of values will tend to fall between a Z-score of -3 to +3. This is why a Z-score threshold of +/- 3 is often used to identify outliers in practice.</p>
<p>For example, here’s a plot of the percentage of outliers found for each variable. I can see that some variables contained more outliers than others. In particular, there were 6 features with more than 3% extreme values.</p>
<div class="cell">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">train</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">id</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">outliers</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/outliers/man/scores.html">scores</a></span><span class="op">(</span>type<span class="op">=</span><span class="st">"z"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/pivot_longer.html">pivot_longer</a></span><span class="op">(</span><span class="fu"><a href="https://tidyselect.r-lib.org/reference/everything.html">everything</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">name</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize</a></span><span class="op">(</span>n_outlier <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">value</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">3</span><span class="op">)</span>,</span>
<span>            pct_outlier <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">value</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">3</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/context.html">n</a></span><span class="op">(</span><span class="op">)</span><span class="op">*</span><span class="fl">100</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="va">pct_outlier</span><span class="op">)</span> <span class="op">-&gt;</span> <span class="va">train_pct_outlier</span></span>
<span></span>
<span><span class="va">train_pct_outlier</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://forcats.tidyverse.org/reference/fct_inorder.html">fct_inorder</a></span><span class="op">(</span><span class="va">name</span><span class="op">)</span>, y <span class="op">=</span> <span class="va">pct_outlier</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html">geom_bar</a></span><span class="op">(</span>stat<span class="op">=</span><span class="st">'identity'</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_flip.html">coord_flip</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">"Feature"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"% values exceeding 3 z-score threshold"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="index_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">train_pct_outlier</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">pct_outlier</span> <span class="op">&gt;</span> <span class="fl">3</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/desc.html">desc</a></span><span class="op">(</span><span class="va">pct_outlier</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 3
  name   n_outlier pct_outlier
  &lt;chr&gt;      &lt;int&gt;       &lt;dbl&gt;
1 NH4_7        137        5.22
2 NH4_1        122        4.65
3 BOD5_3       113        4.3 
4 O2_2         111        4.23
5 NO2_1        104        3.96
6 NH4_2         99        3.77</code></pre>
</div>
</div>
<p>Other options for univariate outlier detection include using the inter-quartile range (IQR) or percentile-based thresholds.</p>
</section><section id="multivariate-outlier-detection" class="level3"><h3 class="anchored" data-anchor-id="multivariate-outlier-detection">Multivariate outlier detection</h3>
<p>Another option is multivariate outlier detection. For multivariate outlier detection, random forest based methods have been growing in popularity within the data science community. There are two methods that I’ll consider here.</p>
<section id="isolation-forest" class="level4"><h4 class="anchored" data-anchor-id="isolation-forest">Isolation forest</h4>
<p>The “isolation forest” works by trying to identify variables that can be isolated in branches when randomly splitting the data. From the <code>isotree</code> <a href="https://search.r-project.org/CRAN/refmans/isotree/html/isolation.forest.html">package documentation</a>:</p>
<blockquote class="blockquote">
<p>Isolation Forest is an algorithm originally developed for outlier detection that consists in splitting sub-samples of the data according to some attribute/feature/column at random. The idea is that, the rarer the observation, the more likely it is that a random uniform split on some feature would put outliers alone in one branch, and the fewer splits it will take to isolate an outlier observation like this.</p>
</blockquote>
<p>Importantly, this method operates at the row level, allowing us to identify anomalous records, but not pinpoint specifically which features on which those records may have been outliers.</p>
<div class="cell">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/david-cortes/isotree">isotree</a></span><span class="op">)</span></span>
<span><span class="va">isofor</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/isotree/man/isolation.forest.html">isolation.forest</a></span><span class="op">(</span><span class="va">train</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">id</span><span class="op">)</span>, ntrees <span class="op">=</span> <span class="fl">500</span>, nthreads <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">iso_preds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">isofor</span>, <span class="va">train</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">id</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">train</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">iso_preds</span><span class="op">)</span>, <span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 37
     id target  O2_1  O2_2  O2_3  O2_4  O2_5  O2_6  O2_7 NH4_1 NH4_2 NH4_3 NH4_4
  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1  2662   15.9  15.9  14.9  8.98  6.17  2.28  8.98  7.15 0.573  0.54 0.208   2.3
# ℹ 24 more variables: NH4_5 &lt;dbl&gt;, NH4_6 &lt;dbl&gt;, NH4_7 &lt;dbl&gt;, NO2_1 &lt;dbl&gt;,
#   NO2_2 &lt;dbl&gt;, NO2_3 &lt;dbl&gt;, NO2_4 &lt;dbl&gt;, NO2_5 &lt;dbl&gt;, NO2_6 &lt;dbl&gt;,
#   NO2_7 &lt;dbl&gt;, NO3_1 &lt;dbl&gt;, NO3_2 &lt;dbl&gt;, NO3_3 &lt;dbl&gt;, NO3_4 &lt;dbl&gt;,
#   NO3_5 &lt;dbl&gt;, NO3_6 &lt;dbl&gt;, NO3_7 &lt;dbl&gt;, BOD5_1 &lt;dbl&gt;, BOD5_2 &lt;dbl&gt;,
#   BOD5_3 &lt;dbl&gt;, BOD5_4 &lt;dbl&gt;, BOD5_5 &lt;dbl&gt;, BOD5_6 &lt;dbl&gt;, BOD5_7 &lt;dbl&gt;</code></pre>
</div>
</div>
</section><section id="outforest" class="level4"><h4 class="anchored" data-anchor-id="outforest">outForest</h4>
<p>The <code>outForest</code> package implements a different random forest method of outlier detection in which each variable is regressed onto all others, and outliers are detected based on the difference between the observed value and the out-of-bag predicted value. This has the advantage of identifying outliers on both a row and column basis, providing more flexibility in terms of how outliers can be dealt with.</p>
<div class="cell">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/mayer79/outForest">outForest</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span><span class="va">outfor</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/outForest/man/outForest.html">outForest</a></span><span class="op">(</span><span class="va">train</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">id</span><span class="op">)</span>, </span>
<span>                    verbose <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="fu">outForest</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/outForest/man/outliers.html">outliers</a></span><span class="op">(</span><span class="va">outfor</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">rmse</span>, <span class="op">-</span><span class="va">threshold</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      row    col observed  predicted    score replacement
453  2003  NH4_5  3026.00 14.0353304 50.63951      12.175
811  1021  NO2_3     2.05  0.1152134 25.71619       0.064
4     237 target    40.78 11.1135703 23.52858       8.100
1315 2556 BOD5_4    55.40  5.8114438 21.74855       5.800
340  2149  NH4_1     4.20  0.4161047 21.17629       0.360
1327  241 BOD5_5    82.45  9.2994377 20.80525       8.400</code></pre>
</div>
</div>
<p>Below we can see the outliers identified for each variable and how anomalous those outliers were. Using this data, I can then choose a threshold and replace anomalous values by imputation. The <code>outForest</code> package provides different methods of imputation out of the box, defaulting to predictive mean matching.</p>
<p>I’ll use this method for detection because it’s multivariate, intuitive, and flexible.</p>
<div class="cell">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">outfor</span>, what <span class="op">=</span> <span class="st">"scores"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="index_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section></section></section><section id="outlier-removal-or-imputation" class="level2"><h2 class="anchored" data-anchor-id="outlier-removal-or-imputation">2. Outlier removal or imputation</h2>
<p>Now that I’ve decided on an outlier detection method, the next step is to decide what to do about the outliers. There’s two main ways outliers can be handled: Removal or imputation. Removal is often an extreme measure that can lead to information loss, so I tend to prefer imputation over removal.</p>
<p>Since I’ve decided to use <code>outForest</code>, I can also use its out-of-the-box imputation methods.</p>
<p>First, I’ll go back to the dataframe containing the outliers that it had detected and try to refine the threshold. By default, it was using a score threshold of 3. But I’m not comfortable with imputing so many values. My gut tells me that if I’m identifying more than 3-5% of the records as outliers, then my threshold is too low and I’m catching too many potentially legitimate values.</p>
<p>Here I can see that a score threshold of 8 yields around 2% outliers on a row-basis. That seems more reasonable</p>
<div class="cell">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="fu">outForest</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/outForest/man/outliers.html">outliers</a></span><span class="op">(</span><span class="va">outfor</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>        <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">replacement</span>, <span class="op">-</span><span class="va">rmse</span>, <span class="op">-</span><span class="va">threshold</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>        <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">score</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">8</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>        <span class="fu"><a href="https://dplyr.tidyverse.org/reference/distinct.html">distinct</a></span><span class="op">(</span><span class="va">row</span><span class="op">)</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">sample_submission</span><span class="op">)</span><span class="op">*</span><span class="fl">100</span><span class="op">)</span>, <span class="fl">1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.9</code></pre>
</div>
</div>
<p>Using this threshold, I will now impute the values.</p>
<div class="cell">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span><span class="va">outfor2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/outForest/man/outForest.html">outForest</a></span><span class="op">(</span><span class="va">train</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">id</span><span class="op">)</span>, </span>
<span>                      verbose <span class="op">=</span> <span class="fl">0</span>, </span>
<span>                      replace <span class="op">=</span> <span class="st">"pmm"</span>,</span>
<span>                      threshold <span class="op">=</span> <span class="fl">8</span><span class="op">)</span></span>
<span><span class="va">train_outlier_adjusted</span> <span class="op">&lt;-</span> <span class="va">outfor2</span><span class="op">$</span><span class="va">Data</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here I can see one of the outliers previously identified, and the value that was imputed for it.</p>
<div class="cell">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">train</span><span class="op">[</span><span class="fl">1021</span>,<span class="op">]</span><span class="op">$</span><span class="va">NO2_3</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.05</code></pre>
</div>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">train_outlier_adjusted</span><span class="op">[</span><span class="fl">1021</span>,<span class="op">]</span><span class="op">$</span><span class="va">NO2_3</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.064</code></pre>
</div>
</div>
<p>And now I can quickly run the random forest model again, with the new imputed training dataset, and compare it against the baseline model.</p>
<p>I see that outlier imputation has improved in-sample performance considerably (which is to be expected since the training dataset on which the cross-validation was performed is now much cleaner!), but it actually had a fairly marginal impact on out-of-sample performance.</p>
<div class="cell">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ranger_fit_1</span> <span class="op">&lt;-</span> <span class="fu">fit_ranger_cv</span><span class="op">(</span><span class="va">train_outlier_adjusted</span>, <span class="va">test</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">id</span><span class="op">)</span>, <span class="st">'outliers imputed'</span><span class="op">)</span></span>
<span></span>
<span><span class="va">ranger_fit_1</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>train_pct_improved <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="op">(</span><span class="va">baseline_fit</span><span class="op">$</span><span class="va">train_perf</span><span class="op">-</span><span class="va">train_perf</span><span class="op">)</span><span class="op">/</span><span class="va">baseline_fit</span><span class="op">$</span><span class="va">train_perf</span><span class="op">*</span><span class="fl">100</span>, <span class="fl">2</span><span class="op">)</span>,</span>
<span>         test_pct_improved <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="op">(</span><span class="va">baseline_fit</span><span class="op">$</span><span class="va">test_perf</span><span class="op">-</span><span class="va">test_perf</span><span class="op">)</span><span class="op">/</span><span class="va">baseline_fit</span><span class="op">$</span><span class="va">test_perf</span><span class="op">*</span><span class="fl">100</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind_rows.html">bind_rows</a></span><span class="op">(</span><span class="va">baseline_fit</span><span class="op">)</span> <span class="op">-&gt;</span> <span class="va">ranger_fit_1</span></span>
<span></span>
<span><span class="va">ranger_fit_1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             model train_perf test_perf train_pct_improved test_pct_improved
1 outliers imputed      1.080     2.128              12.27              0.28
2         baseline      1.231     2.134                 NA                NA</code></pre>
</div>
</div>
</section></section><section id="feature-multicollinearity" class="level1"><h1>Feature multicollinearity</h1>
<p>Another option for data cleanup I can explore is addressing feature multicollinearity. This is when two or more features in the dataset are highly correlated. Like outliers, the impact of this will depend on the model. Random forest models are typically robust to multicollinearity when it comes to model performance, but it can severely impact the feature importances.</p>
<p>Nevertheless, I can explore whether addressing feature multicollinearity would improve model performance.</p>
<p>Some of the features are highly correlated (at r &gt; .6), namely:</p>
<ul>
<li><p><code>NH4_1</code> with <code>NH4_2</code></p></li>
<li><p><code>NO3_1</code> with <code>NO3_2</code></p></li>
<li><p><code>NO3_6</code> with <code>NO3_7</code></p></li>
<li><p><code>NO3_3</code> with <code>NO3_6</code></p></li>
<li><p><code>BOD5_1</code> with <code>BOD5_7</code></p></li>
</ul>
<div class="cell">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">lares</span><span class="fu">::</span><span class="fu"><a href="https://laresbernardo.github.io/lares/reference/corr_cross.html">corr_cross</a></span><span class="op">(</span></span>
<span>  <span class="va">train</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">target</span>, <span class="op">-</span><span class="va">id</span><span class="op">)</span>,</span>
<span>  max_pvalue <span class="op">=</span> <span class="fl">0.05</span>,</span>
<span>  top <span class="op">=</span> <span class="fl">10</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in .font_global(font, quiet = FALSE): Font 'Arial Narrow' is not
installed, has other name, or can't be found</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="index_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>A simple fix for collinearity here would be to remove one variable from each of these pairs. I’ll remove the one with the larger numerical suffix. This is somewhat arbitrary. And fitting the model again, I see that removing collinear features improved in-sample and out-of-sample performance only marginally.</p>
<div class="cell">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">train</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">NH4_2</span>, <span class="op">-</span><span class="va">NO3_2</span>, <span class="op">-</span><span class="va">NO3_7</span>, <span class="op">-</span><span class="va">NO3_6</span>, <span class="op">-</span><span class="va">BOD5_2</span><span class="op">)</span> <span class="op">-&gt;</span> <span class="va">train_with_collinearity_fix</span></span>
<span></span>
<span><span class="va">test</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">NH4_2</span>, <span class="op">-</span><span class="va">NO3_2</span>, <span class="op">-</span><span class="va">NO3_7</span>, <span class="op">-</span><span class="va">NO3_6</span>, <span class="op">-</span><span class="va">BOD5_2</span><span class="op">)</span> <span class="op">-&gt;</span> <span class="va">test_with_collinearity_fix</span></span>
<span></span>
<span><span class="va">ranger_fit_2</span> <span class="op">&lt;-</span> <span class="fu">fit_ranger_cv</span><span class="op">(</span><span class="va">train_with_collinearity_fix</span>, <span class="va">test_with_collinearity_fix</span>, <span class="st">'fix collinearity'</span><span class="op">)</span></span>
<span></span>
<span><span class="va">ranger_fit_2</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>train_pct_improved <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="op">(</span><span class="va">baseline_fit</span><span class="op">$</span><span class="va">train_perf</span><span class="op">-</span><span class="va">train_perf</span><span class="op">)</span><span class="op">/</span><span class="va">baseline_fit</span><span class="op">$</span><span class="va">train_perf</span><span class="op">*</span><span class="fl">100</span>, <span class="fl">2</span><span class="op">)</span>,</span>
<span>         test_pct_improved <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="op">(</span><span class="va">baseline_fit</span><span class="op">$</span><span class="va">test_perf</span><span class="op">-</span><span class="va">test_perf</span><span class="op">)</span><span class="op">/</span><span class="va">baseline_fit</span><span class="op">$</span><span class="va">test_perf</span><span class="op">*</span><span class="fl">100</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind_rows.html">bind_rows</a></span><span class="op">(</span><span class="va">ranger_fit_1</span><span class="op">)</span> <span class="op">-&gt;</span> <span class="va">ranger_fit_2</span></span>
<span></span>
<span><span class="va">ranger_fit_2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             model train_perf test_perf train_pct_improved test_pct_improved
1 fix collinearity      1.217     2.123               1.14              0.52
2 outliers imputed      1.080     2.128              12.27              0.28
3         baseline      1.231     2.134                 NA                NA</code></pre>
</div>
</div>
<p>So to summarize: I’ve used two methods to clean the dataset: 1) random forest based multivariate outlier detection and imputation, and 2) removing multicollinear features. These cleanup techniques achieved only marginal gains in out-of-sample model performance with a random forest model, supporting the common wisdom that random forest models are robust to outliers and multicollinearity.</p>


<!-- -->

</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/tylerburleigh\.com");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><script src="https://giscus.app/client.js" data-repo="tylerburleigh/tylerburleigh.github.io" data-repo-id="R_kgDOKMo8ww" data-category="Blog comments" data-category-id="DIC_kwDOIg6EJc4CSz92" data-mapping="pathname" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script><input type="hidden" id="giscus-base-theme" value="light"><input type="hidden" id="giscus-alt-theme" value="dark"><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb31" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> 'Using random forest based outlier detection to clean a training dataset'</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> 2023-09-08</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "In this post, I explore whether a random forest model can be improved by using random forest based multivariate outlier detection and imputation methods, and by reducing feature multicollinearity. Supporting the common wisdom that random forest models are robust to outliers and multicollinearity, these data cleaning steps led to only marginal improvements in out-of-sample model performance."</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> social-image.png</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="an">twitter-card:</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="co">  image: "social-image.png"</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="an">open-graph:</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="co">  image: "social-image.png"</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="co">  - machine-learning</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="co">  - R</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a><span class="an">freeze:</span><span class="co"> true</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a><span class="fu"># The Challenge</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>For this blog post, I will be tackling the Kaggle compettition <span class="co">[</span><span class="ot">Improve a Fixed Model the Data-Centric Way!</span><span class="co">](https://www.kaggle.com/competitions/playground-series-s3e21/overview)</span></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>This is the challenge of the competition: Improve a dataset that is being used to train a random forest model. The model is fixed, so model performance can only be improved by modifying the dataset. In terms of dataset modifications, there are some additional limitations:</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Rows can be removed, but not added</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Columns cannot be removed or added</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Values in the dataset that are used to train the model can be transformed, but those transformations will not be applied to the validation dataset (which is held out until the challenge comes to an end)</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>This means that many of the tools available to a data scientist for improving an ML model, such as hyperparameter tuning, or data pre-processing applied to both training and test/validation datasets, are not available. The best options, therefore, will be to find ways to clean the training dataset that will yield better performance in the untouched validation dataset.</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>In this post, I will explore whether the training data can be improved using multivariate outlier imputation and by reducing feature multicollinearity. </span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a><span class="fu"># Load libraries</span></span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=F}</span></span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a><span class="in">library(tidyverse)</span></span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a><span class="in">library(tidymodels)</span></span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a><span class="in">library(ranger)</span></span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a><span class="in">library(Metrics)</span></span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a><span class="fu"># Parallel backend</span></span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a><span class="in">```{r,message=F}</span></span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a><span class="in">library(doFuture)</span></span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a><span class="in">registerDoFuture()</span></span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a><span class="in">plan(multisession, workers=4)</span></span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a><span class="fu"># Load the data</span></span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-52"><a href="#cb31-52" aria-hidden="true" tabindex="-1"></a>sample_submission <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">'sample_submission.csv'</span>, <span class="at">show_col_types =</span> F)</span>
<span id="cb31-53"><a href="#cb31-53" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-54"><a href="#cb31-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-55"><a href="#cb31-55" aria-hidden="true" tabindex="-1"></a><span class="fu"># Train/test split</span></span>
<span id="cb31-56"><a href="#cb31-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-59"><a href="#cb31-59" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-60"><a href="#cb31-60" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb31-61"><a href="#cb31-61" aria-hidden="true" tabindex="-1"></a>train_ids <span class="ot">&lt;-</span> (sample_submission <span class="sc">%&gt;%</span> <span class="fu">sample_frac</span>(<span class="fl">0.75</span>))<span class="sc">$</span>id</span>
<span id="cb31-62"><a href="#cb31-62" aria-hidden="true" tabindex="-1"></a>test_ids <span class="ot">&lt;-</span> (sample_submission <span class="sc">%&gt;%</span> <span class="fu">filter</span>(<span class="sc">!</span>id <span class="sc">%in%</span> train_ids))<span class="sc">$</span>id</span>
<span id="cb31-63"><a href="#cb31-63" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> sample_submission <span class="sc">%&gt;%</span> <span class="fu">filter</span>(id <span class="sc">%in%</span> train_ids)</span>
<span id="cb31-64"><a href="#cb31-64" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> sample_submission <span class="sc">%&gt;%</span> <span class="fu">filter</span>(id <span class="sc">%in%</span> test_ids)</span>
<span id="cb31-65"><a href="#cb31-65" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-66"><a href="#cb31-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-67"><a href="#cb31-67" aria-hidden="true" tabindex="-1"></a><span class="fu"># Model pipeline and baseline</span></span>
<span id="cb31-68"><a href="#cb31-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-69"><a href="#cb31-69" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model pipeline</span></span>
<span id="cb31-70"><a href="#cb31-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-71"><a href="#cb31-71" aria-hidden="true" tabindex="-1"></a>Before doing anything else, I want to create a model pipeline function and establish a baseline of model performance. This pipeline and baseline model will allow me to quickly iterate, test, and benchmark changes to the training dataset.</span>
<span id="cb31-72"><a href="#cb31-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-75"><a href="#cb31-75" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-76"><a href="#cb31-76" aria-hidden="true" tabindex="-1"></a>fit_ranger_cv <span class="ot">&lt;-</span> <span class="cf">function</span>(train, test, model_name){</span>
<span id="cb31-77"><a href="#cb31-77" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb31-78"><a href="#cb31-78" aria-hidden="true" tabindex="-1"></a>  model_ranger <span class="ot">&lt;-</span></span>
<span id="cb31-79"><a href="#cb31-79" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The parameters here mirror those that</span></span>
<span id="cb31-80"><a href="#cb31-80" aria-hidden="true" tabindex="-1"></a>    <span class="co"># will be used in the competition model</span></span>
<span id="cb31-81"><a href="#cb31-81" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rand_forest</span>(<span class="at">trees =</span> <span class="dv">1000</span>, </span>
<span id="cb31-82"><a href="#cb31-82" aria-hidden="true" tabindex="-1"></a>                <span class="at">min_n =</span> <span class="dv">7</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb31-83"><a href="#cb31-83" aria-hidden="true" tabindex="-1"></a>    <span class="fu">set_engine</span>(<span class="st">"ranger"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb31-84"><a href="#cb31-84" aria-hidden="true" tabindex="-1"></a>    <span class="fu">set_mode</span>(<span class="st">"regression"</span>)</span>
<span id="cb31-85"><a href="#cb31-85" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-86"><a href="#cb31-86" aria-hidden="true" tabindex="-1"></a>  workflow_ranger <span class="ot">&lt;-</span> </span>
<span id="cb31-87"><a href="#cb31-87" aria-hidden="true" tabindex="-1"></a>    <span class="fu">workflow</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb31-88"><a href="#cb31-88" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_formula</span>(target <span class="sc">~</span> .) <span class="sc">%&gt;%</span> </span>
<span id="cb31-89"><a href="#cb31-89" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_model</span>(model_ranger)</span>
<span id="cb31-90"><a href="#cb31-90" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-91"><a href="#cb31-91" aria-hidden="true" tabindex="-1"></a>  folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(train, <span class="at">v =</span> <span class="dv">5</span>)</span>
<span id="cb31-92"><a href="#cb31-92" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-93"><a href="#cb31-93" aria-hidden="true" tabindex="-1"></a>  fit_ranger <span class="ot">&lt;-</span> </span>
<span id="cb31-94"><a href="#cb31-94" aria-hidden="true" tabindex="-1"></a>    workflow_ranger <span class="sc">%&gt;%</span> </span>
<span id="cb31-95"><a href="#cb31-95" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit_resamples</span>(folds)</span>
<span id="cb31-96"><a href="#cb31-96" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-97"><a href="#cb31-97" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get in-sample performance over resamples</span></span>
<span id="cb31-98"><a href="#cb31-98" aria-hidden="true" tabindex="-1"></a>  <span class="fu">round</span>((fit_ranger <span class="sc">%&gt;%</span></span>
<span id="cb31-99"><a href="#cb31-99" aria-hidden="true" tabindex="-1"></a>    <span class="fu">collect_metrics</span>() <span class="sc">%&gt;%</span></span>
<span id="cb31-100"><a href="#cb31-100" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(.metric <span class="sc">==</span> <span class="st">'rmse'</span>))<span class="sc">$</span>mean, <span class="dv">3</span>) <span class="ot">-&gt;</span> train_perf</span>
<span id="cb31-101"><a href="#cb31-101" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-102"><a href="#cb31-102" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Evaluate performance on out-of-sample (test) data</span></span>
<span id="cb31-103"><a href="#cb31-103" aria-hidden="true" tabindex="-1"></a>  ranger_fit <span class="ot">&lt;-</span> </span>
<span id="cb31-104"><a href="#cb31-104" aria-hidden="true" tabindex="-1"></a>    workflow_ranger <span class="sc">%&gt;%</span></span>
<span id="cb31-105"><a href="#cb31-105" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(train)</span>
<span id="cb31-106"><a href="#cb31-106" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-107"><a href="#cb31-107" aria-hidden="true" tabindex="-1"></a>  <span class="fu">round</span>(<span class="fu">rmse</span>(test<span class="sc">$</span>target, <span class="fu">predict</span>(ranger_fit, test)<span class="sc">$</span>.pred), <span class="dv">3</span>) <span class="ot">-&gt;</span> test_perf</span>
<span id="cb31-108"><a href="#cb31-108" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-109"><a href="#cb31-109" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Combine in-sample and out-of-sample into a dataframe</span></span>
<span id="cb31-110"><a href="#cb31-110" aria-hidden="true" tabindex="-1"></a>  df_perf <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">model =</span> model_name,</span>
<span id="cb31-111"><a href="#cb31-111" aria-hidden="true" tabindex="-1"></a>                        <span class="at">train_perf =</span> train_perf,</span>
<span id="cb31-112"><a href="#cb31-112" aria-hidden="true" tabindex="-1"></a>                        <span class="at">test_perf =</span> test_perf)</span>
<span id="cb31-113"><a href="#cb31-113" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(df_perf)</span>
<span id="cb31-114"><a href="#cb31-114" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb31-115"><a href="#cb31-115" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-116"><a href="#cb31-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-117"><a href="#cb31-117" aria-hidden="true" tabindex="-1"></a><span class="fu">## Baseline performance</span></span>
<span id="cb31-118"><a href="#cb31-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-121"><a href="#cb31-121" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-122"><a href="#cb31-122" aria-hidden="true" tabindex="-1"></a>baseline_fit <span class="ot">&lt;-</span> <span class="fu">fit_ranger_cv</span>(train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>id), test <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>id), <span class="st">'baseline'</span>)</span>
<span id="cb31-123"><a href="#cb31-123" aria-hidden="true" tabindex="-1"></a>baseline_fit</span>
<span id="cb31-124"><a href="#cb31-124" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-125"><a href="#cb31-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-126"><a href="#cb31-126" aria-hidden="true" tabindex="-1"></a>I'm going to run that again so I can be sure the RNG seed is set properly and the results are reproducible -- otherwise I'll be chasing a moving target!</span>
<span id="cb31-127"><a href="#cb31-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-130"><a href="#cb31-130" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-131"><a href="#cb31-131" aria-hidden="true" tabindex="-1"></a>baseline_fit <span class="ot">&lt;-</span> <span class="fu">fit_ranger_cv</span>(train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>id), test <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>id), <span class="st">'baseline'</span>)</span>
<span id="cb31-132"><a href="#cb31-132" aria-hidden="true" tabindex="-1"></a>baseline_fit</span>
<span id="cb31-133"><a href="#cb31-133" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-134"><a href="#cb31-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-135"><a href="#cb31-135" aria-hidden="true" tabindex="-1"></a><span class="fu"># Outlier detection and removal / imputation</span></span>
<span id="cb31-136"><a href="#cb31-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-137"><a href="#cb31-137" aria-hidden="true" tabindex="-1"></a>Outlier detection, sometimes called anomaly detection, involves identifying values that are "extreme" in relation to other records in the dataset. For example, a value might be considered an outlier if it deviates from the mean by more than 3 standard deviations. The impact of outliers on model performance will depend on the model. Linear regressions are fairly sensitive to outliers, whereas random forest models tend to be fairly robust to them. Nevertheless, multivariate outliers can still be a source of noise in training datasets, particularly smaller datasets.</span>
<span id="cb31-138"><a href="#cb31-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-139"><a href="#cb31-139" aria-hidden="true" tabindex="-1"></a>Here I will consider several methods of outlier detection, pick one, and then proceed to consider removal/imputation.</span>
<span id="cb31-140"><a href="#cb31-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-141"><a href="#cb31-141" aria-hidden="true" tabindex="-1"></a><span class="fu">## 1. Outlier detection</span></span>
<span id="cb31-142"><a href="#cb31-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-143"><a href="#cb31-143" aria-hidden="true" tabindex="-1"></a><span class="fu">### Univariate outlier detection</span></span>
<span id="cb31-144"><a href="#cb31-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-145"><a href="#cb31-145" aria-hidden="true" tabindex="-1"></a>One simple univariate outlier detection method involves a "Z-score threshold". In a normally distributed dataset, 99% of values will tend to fall between a Z-score of -3 to +3. This is why a Z-score threshold of +/- 3 is often used to identify outliers in practice.</span>
<span id="cb31-146"><a href="#cb31-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-147"><a href="#cb31-147" aria-hidden="true" tabindex="-1"></a>For example, here's a plot of the percentage of outliers found for each variable. I can see that some variables contained more outliers than others. In particular, there were 6 features with more than 3% extreme values.</span>
<span id="cb31-148"><a href="#cb31-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-151"><a href="#cb31-151" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-152"><a href="#cb31-152" aria-hidden="true" tabindex="-1"></a>train <span class="sc">%&gt;%</span></span>
<span id="cb31-153"><a href="#cb31-153" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>id) <span class="sc">%&gt;%</span></span>
<span id="cb31-154"><a href="#cb31-154" aria-hidden="true" tabindex="-1"></a>  outliers<span class="sc">::</span><span class="fu">scores</span>(<span class="at">type=</span><span class="st">"z"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb31-155"><a href="#cb31-155" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="fu">everything</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb31-156"><a href="#cb31-156" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(name) <span class="sc">%&gt;%</span></span>
<span id="cb31-157"><a href="#cb31-157" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">n_outlier =</span> <span class="fu">sum</span>(<span class="fu">abs</span>(value) <span class="sc">&gt;</span> <span class="dv">3</span>),</span>
<span id="cb31-158"><a href="#cb31-158" aria-hidden="true" tabindex="-1"></a>            <span class="at">pct_outlier =</span> <span class="fu">round</span>(<span class="fu">sum</span>(<span class="fu">abs</span>(value) <span class="sc">&gt;</span> <span class="dv">3</span>)<span class="sc">/</span><span class="fu">n</span>()<span class="sc">*</span><span class="dv">100</span>,<span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb31-159"><a href="#cb31-159" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(pct_outlier) <span class="ot">-&gt;</span> train_pct_outlier</span>
<span id="cb31-160"><a href="#cb31-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-161"><a href="#cb31-161" aria-hidden="true" tabindex="-1"></a>train_pct_outlier <span class="sc">%&gt;%</span></span>
<span id="cb31-162"><a href="#cb31-162" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">fct_inorder</span>(name), <span class="at">y =</span> pct_outlier)) <span class="sc">+</span></span>
<span id="cb31-163"><a href="#cb31-163" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_bar</span>(<span class="at">stat=</span><span class="st">'identity'</span>) <span class="sc">+</span></span>
<span id="cb31-164"><a href="#cb31-164" aria-hidden="true" tabindex="-1"></a>    <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb31-165"><a href="#cb31-165" aria-hidden="true" tabindex="-1"></a>    <span class="fu">xlab</span>(<span class="st">"Feature"</span>) <span class="sc">+</span></span>
<span id="cb31-166"><a href="#cb31-166" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ylab</span>(<span class="st">"% values exceeding 3 z-score threshold"</span>) <span class="sc">+</span></span>
<span id="cb31-167"><a href="#cb31-167" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">3</span>)</span>
<span id="cb31-168"><a href="#cb31-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-169"><a href="#cb31-169" aria-hidden="true" tabindex="-1"></a>train_pct_outlier <span class="sc">%&gt;%</span></span>
<span id="cb31-170"><a href="#cb31-170" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(pct_outlier <span class="sc">&gt;</span> <span class="dv">3</span>) <span class="sc">%&gt;%</span></span>
<span id="cb31-171"><a href="#cb31-171" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(pct_outlier))</span>
<span id="cb31-172"><a href="#cb31-172" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-173"><a href="#cb31-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-174"><a href="#cb31-174" aria-hidden="true" tabindex="-1"></a>Other options for univariate outlier detection include using the inter-quartile range (IQR) or percentile-based thresholds.</span>
<span id="cb31-175"><a href="#cb31-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-176"><a href="#cb31-176" aria-hidden="true" tabindex="-1"></a><span class="fu">### Multivariate outlier detection</span></span>
<span id="cb31-177"><a href="#cb31-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-178"><a href="#cb31-178" aria-hidden="true" tabindex="-1"></a>Another option is multivariate outlier detection. For multivariate outlier detection, random forest based methods have been growing in popularity within the data science community. There are two methods that I'll consider here.</span>
<span id="cb31-179"><a href="#cb31-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-180"><a href="#cb31-180" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Isolation forest</span></span>
<span id="cb31-181"><a href="#cb31-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-182"><a href="#cb31-182" aria-hidden="true" tabindex="-1"></a>The "isolation forest" works by trying to identify variables that can be isolated in branches when randomly splitting the data. From the <span class="in">`isotree`</span> <span class="co">[</span><span class="ot">package documentation</span><span class="co">](https://search.r-project.org/CRAN/refmans/isotree/html/isolation.forest.html)</span>:</span>
<span id="cb31-183"><a href="#cb31-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-184"><a href="#cb31-184" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Isolation Forest is an algorithm originally developed for outlier detection that consists in splitting sub-samples of the data according to some attribute/feature/column at random. The idea is that, the rarer the observation, the more likely it is that a random uniform split on some feature would put outliers alone in one branch, and the fewer splits it will take to isolate an outlier observation like this.</span></span>
<span id="cb31-185"><a href="#cb31-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-186"><a href="#cb31-186" aria-hidden="true" tabindex="-1"></a>Importantly, this method operates at the row level, allowing us to identify anomalous records, but not pinpoint specifically which features on which those records may have been outliers.</span>
<span id="cb31-187"><a href="#cb31-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-190"><a href="#cb31-190" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-191"><a href="#cb31-191" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(isotree)</span>
<span id="cb31-192"><a href="#cb31-192" aria-hidden="true" tabindex="-1"></a>isofor <span class="ot">&lt;-</span> <span class="fu">isolation.forest</span>(train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>id), <span class="at">ntrees =</span> <span class="dv">500</span>, <span class="at">nthreads =</span> <span class="dv">4</span>)</span>
<span id="cb31-193"><a href="#cb31-193" aria-hidden="true" tabindex="-1"></a>iso_preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(isofor, train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>id))</span>
<span id="cb31-194"><a href="#cb31-194" aria-hidden="true" tabindex="-1"></a>train[<span class="fu">which.max</span>(iso_preds), ]</span>
<span id="cb31-195"><a href="#cb31-195" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-196"><a href="#cb31-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-197"><a href="#cb31-197" aria-hidden="true" tabindex="-1"></a><span class="fu">#### outForest</span></span>
<span id="cb31-198"><a href="#cb31-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-199"><a href="#cb31-199" aria-hidden="true" tabindex="-1"></a>The <span class="in">`outForest`</span> package implements a different random forest method of outlier detection in which each variable is regressed onto all others, and outliers are detected based on the difference between the observed value and the out-of-bag predicted value. This has the advantage of identifying outliers on both a row and column basis, providing more flexibility in terms of how outliers can be dealt with.</span>
<span id="cb31-200"><a href="#cb31-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-201"><a href="#cb31-201" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=F}</span></span>
<span id="cb31-202"><a href="#cb31-202" aria-hidden="true" tabindex="-1"></a><span class="in">library(outForest)</span></span>
<span id="cb31-203"><a href="#cb31-203" aria-hidden="true" tabindex="-1"></a><span class="in">set.seed(42)</span></span>
<span id="cb31-204"><a href="#cb31-204" aria-hidden="true" tabindex="-1"></a><span class="in">outfor &lt;- outForest(train %&gt;% select(-id), </span></span>
<span id="cb31-205"><a href="#cb31-205" aria-hidden="true" tabindex="-1"></a><span class="in">                    verbose = 0)</span></span>
<span id="cb31-206"><a href="#cb31-206" aria-hidden="true" tabindex="-1"></a><span class="in">outForest::outliers(outfor) %&gt;%</span></span>
<span id="cb31-207"><a href="#cb31-207" aria-hidden="true" tabindex="-1"></a><span class="in">  select(-rmse, -threshold) %&gt;%</span></span>
<span id="cb31-208"><a href="#cb31-208" aria-hidden="true" tabindex="-1"></a><span class="in">  head()</span></span>
<span id="cb31-209"><a href="#cb31-209" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-210"><a href="#cb31-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-211"><a href="#cb31-211" aria-hidden="true" tabindex="-1"></a>Below we can see the outliers identified for each variable and how anomalous those outliers were. Using this data, I can then choose a threshold and replace anomalous values by imputation. The <span class="in">`outForest`</span> package provides different methods of imputation out of the box, defaulting to predictive mean matching.</span>
<span id="cb31-212"><a href="#cb31-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-213"><a href="#cb31-213" aria-hidden="true" tabindex="-1"></a>I'll use this method for detection because it's multivariate, intuitive, and flexible.</span>
<span id="cb31-214"><a href="#cb31-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-217"><a href="#cb31-217" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-218"><a href="#cb31-218" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(outfor, <span class="at">what =</span> <span class="st">"scores"</span>)</span>
<span id="cb31-219"><a href="#cb31-219" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-220"><a href="#cb31-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-221"><a href="#cb31-221" aria-hidden="true" tabindex="-1"></a><span class="fu">## 2. Outlier removal or imputation</span></span>
<span id="cb31-222"><a href="#cb31-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-223"><a href="#cb31-223" aria-hidden="true" tabindex="-1"></a>Now that I've decided on an outlier detection method, the next step is to decide what to do about the outliers. There's two main ways outliers can be handled: Removal or imputation. Removal is often an extreme measure that can lead to information loss, so I tend to prefer imputation over removal.</span>
<span id="cb31-224"><a href="#cb31-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-225"><a href="#cb31-225" aria-hidden="true" tabindex="-1"></a>Since I've decided to use <span class="in">`outForest`</span>, I can also use its out-of-the-box imputation methods.</span>
<span id="cb31-226"><a href="#cb31-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-227"><a href="#cb31-227" aria-hidden="true" tabindex="-1"></a>First, I'll go back to the dataframe containing the outliers that it had detected and try to refine the threshold. By default, it was using a score threshold of 3. But I'm not comfortable with imputing so many values. My gut tells me that if I'm identifying more than 3-5% of the records as outliers, then my threshold is too low and I'm catching too many potentially legitimate values.</span>
<span id="cb31-228"><a href="#cb31-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-229"><a href="#cb31-229" aria-hidden="true" tabindex="-1"></a>Here I can see that a score threshold of 8 yields around 2% outliers on a row-basis. That seems more reasonable</span>
<span id="cb31-230"><a href="#cb31-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-233"><a href="#cb31-233" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-234"><a href="#cb31-234" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>((<span class="fu">nrow</span>(outForest<span class="sc">::</span><span class="fu">outliers</span>(outfor) <span class="sc">%&gt;%</span></span>
<span id="cb31-235"><a href="#cb31-235" aria-hidden="true" tabindex="-1"></a>        <span class="fu">select</span>(<span class="sc">-</span>replacement, <span class="sc">-</span>rmse, <span class="sc">-</span>threshold) <span class="sc">%&gt;%</span></span>
<span id="cb31-236"><a href="#cb31-236" aria-hidden="true" tabindex="-1"></a>        <span class="fu">filter</span>(<span class="fu">abs</span>(score) <span class="sc">&gt;</span> <span class="dv">8</span>) <span class="sc">%&gt;%</span></span>
<span id="cb31-237"><a href="#cb31-237" aria-hidden="true" tabindex="-1"></a>        <span class="fu">distinct</span>(row))<span class="sc">/</span><span class="fu">nrow</span>(sample_submission)<span class="sc">*</span><span class="dv">100</span>), <span class="dv">1</span>)</span>
<span id="cb31-238"><a href="#cb31-238" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-239"><a href="#cb31-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-240"><a href="#cb31-240" aria-hidden="true" tabindex="-1"></a>Using this threshold, I will now impute the values.</span>
<span id="cb31-241"><a href="#cb31-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-244"><a href="#cb31-244" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-245"><a href="#cb31-245" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb31-246"><a href="#cb31-246" aria-hidden="true" tabindex="-1"></a>outfor2 <span class="ot">&lt;-</span> <span class="fu">outForest</span>(train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>id), </span>
<span id="cb31-247"><a href="#cb31-247" aria-hidden="true" tabindex="-1"></a>                      <span class="at">verbose =</span> <span class="dv">0</span>, </span>
<span id="cb31-248"><a href="#cb31-248" aria-hidden="true" tabindex="-1"></a>                      <span class="at">replace =</span> <span class="st">"pmm"</span>,</span>
<span id="cb31-249"><a href="#cb31-249" aria-hidden="true" tabindex="-1"></a>                      <span class="at">threshold =</span> <span class="dv">8</span>)</span>
<span id="cb31-250"><a href="#cb31-250" aria-hidden="true" tabindex="-1"></a>train_outlier_adjusted <span class="ot">&lt;-</span> outfor2<span class="sc">$</span>Data</span>
<span id="cb31-251"><a href="#cb31-251" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-252"><a href="#cb31-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-253"><a href="#cb31-253" aria-hidden="true" tabindex="-1"></a>Here I can see one of the outliers previously identified, and the value that was imputed for it.</span>
<span id="cb31-254"><a href="#cb31-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-257"><a href="#cb31-257" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-258"><a href="#cb31-258" aria-hidden="true" tabindex="-1"></a>train[<span class="dv">1021</span>,]<span class="sc">$</span>NO2_3</span>
<span id="cb31-259"><a href="#cb31-259" aria-hidden="true" tabindex="-1"></a>train_outlier_adjusted[<span class="dv">1021</span>,]<span class="sc">$</span>NO2_3</span>
<span id="cb31-260"><a href="#cb31-260" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-261"><a href="#cb31-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-262"><a href="#cb31-262" aria-hidden="true" tabindex="-1"></a>And now I can quickly run the random forest model again, with the new imputed training dataset, and compare it against the baseline model.</span>
<span id="cb31-263"><a href="#cb31-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-264"><a href="#cb31-264" aria-hidden="true" tabindex="-1"></a>I see that outlier imputation has improved in-sample performance considerably (which is to be expected since the training dataset on which the cross-validation was performed is now much cleaner!), but it actually had a fairly marginal impact on out-of-sample performance.</span>
<span id="cb31-265"><a href="#cb31-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-268"><a href="#cb31-268" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-269"><a href="#cb31-269" aria-hidden="true" tabindex="-1"></a>ranger_fit_1 <span class="ot">&lt;-</span> <span class="fu">fit_ranger_cv</span>(train_outlier_adjusted, test <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>id), <span class="st">'outliers imputed'</span>)</span>
<span id="cb31-270"><a href="#cb31-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-271"><a href="#cb31-271" aria-hidden="true" tabindex="-1"></a>ranger_fit_1 <span class="sc">%&gt;%</span></span>
<span id="cb31-272"><a href="#cb31-272" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">train_pct_improved =</span> <span class="fu">round</span>((baseline_fit<span class="sc">$</span>train_perf<span class="sc">-</span>train_perf)<span class="sc">/</span>baseline_fit<span class="sc">$</span>train_perf<span class="sc">*</span><span class="dv">100</span>, <span class="dv">2</span>),</span>
<span id="cb31-273"><a href="#cb31-273" aria-hidden="true" tabindex="-1"></a>         <span class="at">test_pct_improved =</span> <span class="fu">round</span>((baseline_fit<span class="sc">$</span>test_perf<span class="sc">-</span>test_perf)<span class="sc">/</span>baseline_fit<span class="sc">$</span>test_perf<span class="sc">*</span><span class="dv">100</span>, <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb31-274"><a href="#cb31-274" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(baseline_fit) <span class="ot">-&gt;</span> ranger_fit_1</span>
<span id="cb31-275"><a href="#cb31-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-276"><a href="#cb31-276" aria-hidden="true" tabindex="-1"></a>ranger_fit_1</span>
<span id="cb31-277"><a href="#cb31-277" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-278"><a href="#cb31-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-279"><a href="#cb31-279" aria-hidden="true" tabindex="-1"></a><span class="fu"># Feature multicollinearity</span></span>
<span id="cb31-280"><a href="#cb31-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-281"><a href="#cb31-281" aria-hidden="true" tabindex="-1"></a>Another option for data cleanup I can explore is addressing feature multicollinearity. This is when two or more features in the dataset are highly correlated. Like outliers, the impact of this will depend on the model. Random forest models are typically robust to multicollinearity when it comes to model performance, but it can severely impact the feature importances.</span>
<span id="cb31-282"><a href="#cb31-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-283"><a href="#cb31-283" aria-hidden="true" tabindex="-1"></a>Nevertheless, I can explore whether addressing feature multicollinearity would improve model performance.</span>
<span id="cb31-284"><a href="#cb31-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-285"><a href="#cb31-285" aria-hidden="true" tabindex="-1"></a>Some of the features are highly correlated (at r &gt; .6), namely:</span>
<span id="cb31-286"><a href="#cb31-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-287"><a href="#cb31-287" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`NH4_1`</span> with <span class="in">`NH4_2`</span></span>
<span id="cb31-288"><a href="#cb31-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-289"><a href="#cb31-289" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`NO3_1`</span> with <span class="in">`NO3_2`</span></span>
<span id="cb31-290"><a href="#cb31-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-291"><a href="#cb31-291" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`NO3_6`</span> with <span class="in">`NO3_7`</span></span>
<span id="cb31-292"><a href="#cb31-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-293"><a href="#cb31-293" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`NO3_3`</span> with <span class="in">`NO3_6`</span></span>
<span id="cb31-294"><a href="#cb31-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-295"><a href="#cb31-295" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`BOD5_1`</span> with <span class="in">`BOD5_7`</span></span>
<span id="cb31-296"><a href="#cb31-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-297"><a href="#cb31-297" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=F}</span></span>
<span id="cb31-298"><a href="#cb31-298" aria-hidden="true" tabindex="-1"></a><span class="in">lares::corr_cross(</span></span>
<span id="cb31-299"><a href="#cb31-299" aria-hidden="true" tabindex="-1"></a><span class="in">  train %&gt;% select(-target, -id),</span></span>
<span id="cb31-300"><a href="#cb31-300" aria-hidden="true" tabindex="-1"></a><span class="in">  max_pvalue = 0.05,</span></span>
<span id="cb31-301"><a href="#cb31-301" aria-hidden="true" tabindex="-1"></a><span class="in">  top = 10</span></span>
<span id="cb31-302"><a href="#cb31-302" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb31-303"><a href="#cb31-303" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-304"><a href="#cb31-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-305"><a href="#cb31-305" aria-hidden="true" tabindex="-1"></a>A simple fix for collinearity here would be to remove one variable from each of these pairs. I'll remove the one with the larger numerical suffix. This is somewhat arbitrary. And fitting the model again, I see that removing collinear features improved in-sample and out-of-sample performance only marginally.</span>
<span id="cb31-306"><a href="#cb31-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-309"><a href="#cb31-309" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-310"><a href="#cb31-310" aria-hidden="true" tabindex="-1"></a>train <span class="sc">%&gt;%</span></span>
<span id="cb31-311"><a href="#cb31-311" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>NH4_2, <span class="sc">-</span>NO3_2, <span class="sc">-</span>NO3_7, <span class="sc">-</span>NO3_6, <span class="sc">-</span>BOD5_2) <span class="ot">-&gt;</span> train_with_collinearity_fix</span>
<span id="cb31-312"><a href="#cb31-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-313"><a href="#cb31-313" aria-hidden="true" tabindex="-1"></a>test <span class="sc">%&gt;%</span></span>
<span id="cb31-314"><a href="#cb31-314" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>NH4_2, <span class="sc">-</span>NO3_2, <span class="sc">-</span>NO3_7, <span class="sc">-</span>NO3_6, <span class="sc">-</span>BOD5_2) <span class="ot">-&gt;</span> test_with_collinearity_fix</span>
<span id="cb31-315"><a href="#cb31-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-316"><a href="#cb31-316" aria-hidden="true" tabindex="-1"></a>ranger_fit_2 <span class="ot">&lt;-</span> <span class="fu">fit_ranger_cv</span>(train_with_collinearity_fix, test_with_collinearity_fix, <span class="st">'fix collinearity'</span>)</span>
<span id="cb31-317"><a href="#cb31-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-318"><a href="#cb31-318" aria-hidden="true" tabindex="-1"></a>ranger_fit_2 <span class="sc">%&gt;%</span></span>
<span id="cb31-319"><a href="#cb31-319" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">train_pct_improved =</span> <span class="fu">round</span>((baseline_fit<span class="sc">$</span>train_perf<span class="sc">-</span>train_perf)<span class="sc">/</span>baseline_fit<span class="sc">$</span>train_perf<span class="sc">*</span><span class="dv">100</span>, <span class="dv">2</span>),</span>
<span id="cb31-320"><a href="#cb31-320" aria-hidden="true" tabindex="-1"></a>         <span class="at">test_pct_improved =</span> <span class="fu">round</span>((baseline_fit<span class="sc">$</span>test_perf<span class="sc">-</span>test_perf)<span class="sc">/</span>baseline_fit<span class="sc">$</span>test_perf<span class="sc">*</span><span class="dv">100</span>, <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb31-321"><a href="#cb31-321" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(ranger_fit_1) <span class="ot">-&gt;</span> ranger_fit_2</span>
<span id="cb31-322"><a href="#cb31-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-323"><a href="#cb31-323" aria-hidden="true" tabindex="-1"></a>ranger_fit_2</span>
<span id="cb31-324"><a href="#cb31-324" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-325"><a href="#cb31-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-326"><a href="#cb31-326" aria-hidden="true" tabindex="-1"></a>So to summarize: I've used two methods to clean the dataset: 1) random forest based multivariate outlier detection and imputation, and 2) removing multicollinear features. These cleanup techniques achieved only marginal gains in out-of-sample model performance with a random forest model, supporting the common wisdom that random forest models are robust to outliers and multicollinearity.</span>
<span id="cb31-327"><a href="#cb31-327" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p><span class="faux-block"><a href="https://creativecommons.org/licenses/by/4.0/"><i class="fa-brands fa-creative-commons" aria-label="creative-commons"></i></a> 2014–2025 Tyler Burleigh</span></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p><span class="faux-block">Made with <i class="fa-brands fa-r-project" aria-label="r-project"></i>, <a href="https://quarto.org/">Quarto</a>, and the <a href="https://github.com/andrewheiss/ath-quarto">ath-quarto</a> theme</span></p>
</div>
  </div>
</footer>


</body></html>